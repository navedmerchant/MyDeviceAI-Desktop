import { app, BrowserWindow, ipcMain } from 'electron';
import {
  getLlamaInstallStatus,
  installLatestLlama,
  ensureLlamaServer,
  LlamaSetupProgress,
  stopLlamaServer,
} from './llamaSetup';
// This allows TypeScript to pick up the magic constants that's auto-generated by Forge's Webpack
// plugin that tells the Electron app where to look for the Webpack-bundled app code (depending on
// whether you're running in development or production).
declare const MAIN_WINDOW_WEBPACK_ENTRY: string;
declare const MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY: string;

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
if (require('electron-squirrel-startup')) {
  app.quit();
}

const LOG_PREFIX_MAIN = '[Main]';

function logMain(message: string, extra?: Record<string, unknown>): void {
  if (extra) {
    // eslint-disable-next-line no-console
    console.log(`${LOG_PREFIX_MAIN} ${message}`, extra);
  } else {
    // eslint-disable-next-line no-console
    console.log(`${LOG_PREFIX_MAIN} ${message}`);
  }
}

function logMainError(message: string, error?: unknown, extra?: Record<string, unknown>): void {
  // eslint-disable-next-line no-console
  console.error(`${LOG_PREFIX_MAIN} ${message}`, {
    error:
      error instanceof Error
        ? { name: error.name, message: error.message, stack: error.stack }
        : error,
    ...extra,
  });
}

const createWindow = async (): Promise<void> => {
  logMain('createWindow invoked');
  const status = await getLlamaInstallStatus().catch((err: unknown) => {
    logMainError('getLlamaInstallStatus failed during createWindow', err);
    // Fallback shape keeps type-narrowing clear for downstream usage.
    return { installed: false, error: 'status-check-failed' } as const;
  });

  // Narrow status to the known union from llamaSetup.ts so TS understands version/binaryPath.
  const normalizedStatus: {
    installed: boolean;
    version?: string;
    binaryPath?: string;
    error?: string;
  } = status as any;

  logMain('Llama install status at startup', normalizedStatus as any);

  // Create the browser window.
  const mainWindow = new BrowserWindow({
    height: 600,
    width: 800,
    webPreferences: {
      preload: MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY,
    },
  });

  // Initial route state decided by install status; renderer uses this to show setup screen when needed.
  const startupParams = new URLSearchParams();
  startupParams.set('llamaInstalled', normalizedStatus.installed ? '1' : '0');
  if (normalizedStatus.version) {
    startupParams.set('llamaVersion', normalizedStatus.version);
  }

  // and load the index.html of the app with query params.
  const startUrl = `${MAIN_WINDOW_WEBPACK_ENTRY}?${startupParams.toString()}`;
  logMain('Loading main window URL', { url: startUrl });
  mainWindow.loadURL(startUrl);

  // Open the DevTools (optional; comment out in production).
  mainWindow.webContents.openDevTools();
};

// This method will be called when Electron has finished
// initialization and is ready to create browser windows.
// Some APIs can only be used after this event occurs.
app.on('ready', () => {
  logMain('Electron app ready event received');
  void createWindow();
});

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the user quits
// explicitly with Cmd + Q.
app.on('window-all-closed', () => {
  logMain('All windows closed', { platform: process.platform });
  if (process.platform !== 'darwin') {
    logMain('Quitting app because platform is not darwin');
    app.quit();
  }
});

// Ensure the managed llama-server is stopped when Electron begins quitting.
// This guarantees we don't leak the background process.
app.on('before-quit', () => {
  logMain('App before-quit: stopping managed llama-server if running');
  stopLlamaServer();
});

app.on('activate', () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  logMain('App activate event');
  if (BrowserWindow.getAllWindows().length === 0) {
    logMain('No existing windows, creating a new one');
    void createWindow();
  }
});

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and import them here.

// IPC wiring for llama.cpp setup (main & preload will use these channels).
// Guard against double-registration if this file is executed more than once
// (e.g. by hot-reload).
if (!ipcMain.listeners('llama-get-status').length) {
  logMain('Registering IPC handler llama-get-status');
  ipcMain.handle('llama-get-status', async () => {
    try {
      const status = await getLlamaInstallStatus();
      logMain('IPC llama-get-status resolved', status as any);
      return status;
    } catch (err) {
      logMainError('IPC llama-get-status failed', err);
      return { installed: false, error: 'status-error' };
    }
  });
}

if (!ipcMain.listeners('llama-install-latest').length) {
  logMain('Registering IPC handler llama-install-latest');
  ipcMain.handle('llama-install-latest', async (event) => {
    const webContents = event.sender;
    logMain('IPC llama-install-latest invoked');

    const progressCallback = (p: LlamaSetupProgress) => {
      // eslint-disable-next-line no-console
      console.log('[LlamaSetup][IPC] progress', p);
      webContents.send('llama-install-progress', p);
    };

    const result = await installLatestLlama(progressCallback);
    logMain('IPC llama-install-latest completed', result as any);
    return result;
  });
}

// Start / ensure llama-server on an available random port with Qwen3-4B GGUF.
if (!ipcMain.listeners('llama-ensure-server').length) {
  logMain('Registering IPC handler llama-ensure-server');
  ipcMain.handle('llama-ensure-server', async (event) => {
    const webContents = event.sender;
    logMain('IPC llama-ensure-server invoked');

    const progressCallback = (p: LlamaSetupProgress) => {
      // eslint-disable-next-line no-console
      console.log('[LlamaSetup][IPC] ensure-server progress', p);
      webContents.send('llama-install-progress', p);
    };

    const result = await ensureLlamaServer(progressCallback);
    logMain('IPC llama-ensure-server completed', result as any);
    return result;
  });
}

// Allow preload/renderer to query currently known managed server endpoint.
// Implementation here is lightweight: ensureLlamaServer already returns the
// endpoint; we reuse it here so preload can discover the active port.
if (!ipcMain.listeners('llama-server-get-endpoint').length) {
  logMain('Registering IPC handler llama-server-get-endpoint');
  ipcMain.handle('llama-server-get-endpoint', async () => {
    logMain('IPC llama-server-get-endpoint invoked');
    const result = await ensureLlamaServer();
    if (result.ok) {
      logMain('llama-server-get-endpoint OK', { endpoint: result.endpoint });
      return { ok: true, endpoint: result.endpoint };
    }
    logMainError('llama-server-get-endpoint failed', undefined, {
      error: (result as { ok: false; error: string }).error,
    });
    return { ok: false, error: (result as { ok: false; error: string }).error };
  });
}
